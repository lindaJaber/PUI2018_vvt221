{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "/nfshome/vvt221/PUIdata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#imports downloader\n",
    "\n",
    "from scipy import stats\n",
    "%pylab inline\n",
    "\n",
    "import os\n",
    "#this makes my plots pretty! but it is totally not mandatory to do it\n",
    "import json\n",
    "os.environ[\"PUI2018\"] = \"%s/PUI2018\"%os.getenv(\"HOME\")\n",
    "os.environ[\"PUIDATA\"] = \"%s/PUIdata\"%os.getenv(\"HOME\")\n",
    "if os.getenv ('PUI2018') is None:\n",
    "    print (\"Must set env variable PUI2018\")\n",
    "if os.getenv ('PUIDATA') is None:\n",
    "    print (\"Must set env variable PUI2018\")\n",
    "print(os.getenv(\"PUIDATA\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCitiBikeCSV(datestring):\n",
    "    print (\"Downloading\", datestring)\n",
    "    ### First I will check that it is not already there\n",
    "    if not os.path.isfile(os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata.csv\"):\n",
    "        if os.path.isfile(datestring + \"-citibike-tripdata.csv\"):\n",
    "            # if in the current dir just move it\n",
    "            if os.system(\"mv \" + datestring + \"-citibike-tripdata.csv \" + os.getenv(\"PUIDATA\")):\n",
    "                print (\"Error moving file!, Please check!\")\n",
    "        #otherwise start looking for the zip file\n",
    "        else:\n",
    "            if not os.path.isfile(os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata.zip\"):\n",
    "                if not os.path.isfile(datestring + \"-citibike-tripdata.zip\"):\n",
    "                    os.system(\"curl -O https://s3.amazonaws.com/tripdata/\"  + datestring +\"-citibike-tripdata.zip\")\n",
    "                ###  To move it I use the os.system() functions to run bash commands with arguments\n",
    "                os.system(\"mv \" + datestring + \"-citibike-tripdata.zip \" + os.getenv(\"PUIDATA\"))\n",
    "            ### unzip the csv \n",
    "            os.system(\"unzip \" + os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata.zip\")\n",
    "            ## NOTE: old csv citibike data had a different name structure. \n",
    "            if '2014' in datestring:\n",
    "                os.system(\"mv \" + datestring[:4] + '-' +  datestring[4:] + \n",
    "                          \"\\ -\\ Citi\\ Bike\\ trip\\ data.csv \" + datestring + \"-citibike-tripdata.csv\")\n",
    "            os.system(\"mv \" + datestring + \"-citibike-tripdata.csv \" + os.getenv(\"PUIDATA\"))\n",
    "    ### One final check:\n",
    "    if not os.path.isfile(os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata.csv\"):\n",
    "        print (\"WARNING!!! something is wrong: the file is not there!\")\n",
    "\n",
    "    else:\n",
    "        print (\"file in place, you can continue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 201601\n",
      "file in place, you can continue\n",
      "Downloading 201607\n",
      "file in place, you can continue\n"
     ]
    }
   ],
   "source": [
    "datestring_Jan = '201601'\n",
    "getCitiBikeCSV(datestring_Jan)\n",
    "datestring_Jul = '201607'\n",
    "getCitiBikeCSV(datestring_Jul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### We will perform the analysis for the months January and July, one winter and one summer month each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : Read the csv files of all the months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Jan = pd.read_csv(os.getenv(\"PUIDATA\") + \"/201601-citibike-tripdata.csv\")\n",
    "\n",
    "df_Jul = pd.read_csv(os.getenv(\"PUIDATA\") + \"/201607-citibike-tripdata.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 : Concatenate all the dataframes into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = pd.concat([df_Jan,df_Jul],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripduration                 int64\n",
       "starttime                   object\n",
       "stoptime                    object\n",
       "start station id             int64\n",
       "start station name          object\n",
       "start station latitude     float64\n",
       "start station longitude    float64\n",
       "end station id               int64\n",
       "end station name            object\n",
       "end station latitude       float64\n",
       "end station longitude      float64\n",
       "bikeid                       int64\n",
       "usertype                    object\n",
       "birth year                 float64\n",
       "gender                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null hypothesis\n",
    "\n",
    "## $H_0$ : There is no statistical difference in the distribution of tripduration of the day(6.00 AM -6.00PM) and the night (6.00 PM -6.00AM) riders, p =0.05\n",
    "\n",
    "$\\alpha$=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['date'] = pd.to_datetime(df_2016['stoptime'],infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>923</td>\n",
       "      <td>1/1/2016 00:00:41</td>\n",
       "      <td>1/1/2016 00:16:04</td>\n",
       "      <td>268</td>\n",
       "      <td>Howard St &amp; Centre St</td>\n",
       "      <td>40.719105</td>\n",
       "      <td>-73.999733</td>\n",
       "      <td>3002</td>\n",
       "      <td>South End Ave &amp; Liberty St</td>\n",
       "      <td>40.711512</td>\n",
       "      <td>-74.015756</td>\n",
       "      <td>22285</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:16:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>379</td>\n",
       "      <td>1/1/2016 00:00:45</td>\n",
       "      <td>1/1/2016 00:07:04</td>\n",
       "      <td>476</td>\n",
       "      <td>E 31 St &amp; 3 Ave</td>\n",
       "      <td>40.743943</td>\n",
       "      <td>-73.979661</td>\n",
       "      <td>498</td>\n",
       "      <td>Broadway &amp; W 32 St</td>\n",
       "      <td>40.748549</td>\n",
       "      <td>-73.988084</td>\n",
       "      <td>17827</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:07:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589</td>\n",
       "      <td>1/1/2016 00:00:48</td>\n",
       "      <td>1/1/2016 00:10:37</td>\n",
       "      <td>489</td>\n",
       "      <td>10 Ave &amp; W 28 St</td>\n",
       "      <td>40.750664</td>\n",
       "      <td>-74.001768</td>\n",
       "      <td>284</td>\n",
       "      <td>Greenwich Ave &amp; 8 Ave</td>\n",
       "      <td>40.739017</td>\n",
       "      <td>-74.002638</td>\n",
       "      <td>21997</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:10:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>889</td>\n",
       "      <td>1/1/2016 00:01:06</td>\n",
       "      <td>1/1/2016 00:15:56</td>\n",
       "      <td>268</td>\n",
       "      <td>Howard St &amp; Centre St</td>\n",
       "      <td>40.719105</td>\n",
       "      <td>-73.999733</td>\n",
       "      <td>3002</td>\n",
       "      <td>South End Ave &amp; Liberty St</td>\n",
       "      <td>40.711512</td>\n",
       "      <td>-74.015756</td>\n",
       "      <td>22794</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:15:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1480</td>\n",
       "      <td>1/1/2016 00:01:12</td>\n",
       "      <td>1/1/2016 00:25:52</td>\n",
       "      <td>2006</td>\n",
       "      <td>Central Park S &amp; 6 Ave</td>\n",
       "      <td>40.765909</td>\n",
       "      <td>-73.976342</td>\n",
       "      <td>2006</td>\n",
       "      <td>Central Park S &amp; 6 Ave</td>\n",
       "      <td>40.765909</td>\n",
       "      <td>-73.976342</td>\n",
       "      <td>14562</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:25:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration          starttime           stoptime  start station id  \\\n",
       "0           923  1/1/2016 00:00:41  1/1/2016 00:16:04               268   \n",
       "1           379  1/1/2016 00:00:45  1/1/2016 00:07:04               476   \n",
       "2           589  1/1/2016 00:00:48  1/1/2016 00:10:37               489   \n",
       "3           889  1/1/2016 00:01:06  1/1/2016 00:15:56               268   \n",
       "4          1480  1/1/2016 00:01:12  1/1/2016 00:25:52              2006   \n",
       "\n",
       "       start station name  start station latitude  start station longitude  \\\n",
       "0   Howard St & Centre St               40.719105               -73.999733   \n",
       "1         E 31 St & 3 Ave               40.743943               -73.979661   \n",
       "2        10 Ave & W 28 St               40.750664               -74.001768   \n",
       "3   Howard St & Centre St               40.719105               -73.999733   \n",
       "4  Central Park S & 6 Ave               40.765909               -73.976342   \n",
       "\n",
       "   end station id            end station name  end station latitude  \\\n",
       "0            3002  South End Ave & Liberty St             40.711512   \n",
       "1             498          Broadway & W 32 St             40.748549   \n",
       "2             284       Greenwich Ave & 8 Ave             40.739017   \n",
       "3            3002  South End Ave & Liberty St             40.711512   \n",
       "4            2006      Central Park S & 6 Ave             40.765909   \n",
       "\n",
       "   end station longitude  bikeid    usertype  birth year  gender  \\\n",
       "0             -74.015756   22285  Subscriber      1958.0       1   \n",
       "1             -73.988084   17827  Subscriber      1969.0       1   \n",
       "2             -74.002638   21997  Subscriber      1982.0       2   \n",
       "3             -74.015756   22794  Subscriber      1961.0       2   \n",
       "4             -73.976342   14562  Subscriber      1952.0       1   \n",
       "\n",
       "                 date  \n",
       "0 2016-01-01 00:16:04  \n",
       "1 2016-01-01 00:07:04  \n",
       "2 2016-01-01 00:10:37  \n",
       "3 2016-01-01 00:15:56  \n",
       "4 2016-01-01 00:25:52  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Divide the data frame into day rides start time and night time start time\n",
    "###### 1. define what is morning start time 6.00 AM ---->  6.00 PM\n",
    "###### 2. define what is night start time   6.00 PM ---->  6.00 AM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayriders = df_2016[['start station id','tripduration']][(df_2016['date'].dt.hour >=6) & (df_2016['date'].dt.hour < 18)]\n",
    "nightriders = df_2016[['start station id','tripduration']][(df_2016['date'].dt.hour>=18) | (df_2016['date'].dt.hour < 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayriders.dropna(inplace=True)\n",
    "nightriders.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.268759e+06\n",
       "mean     9.321024e+02\n",
       "std      1.035736e+04\n",
       "min      6.100000e+01\n",
       "25%      3.750000e+02\n",
       "50%      6.120000e+02\n",
       "75%      1.035000e+03\n",
       "max      6.707533e+06\n",
       "Name: tripduration, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dayriders['tripduration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6.208290e+05\n",
       "mean     1.014104e+03\n",
       "std      1.565333e+04\n",
       "min      6.100000e+01\n",
       "25%      3.890000e+02\n",
       "50%      6.530000e+02\n",
       "75%      1.110000e+03\n",
       "max      6.177145e+06\n",
       "Name: tripduration, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nightriders['tripduration'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'counts')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "ax = nightriders.plot( y='tripduration',kind='box')\n",
    "ax.set_ylabel('counts')\n",
    "ax.set_title('trip duration during nightime')\n",
    "ay = dayriders.plot( y='tripduration',kind='box')\n",
    "ay.set_title('trip duration during daytime')\n",
    "ay.set_ylabel('counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fig 1: The spread of the tripduration values is large .The two boxplots are thus able to show only the outliers. Let us visualize the tripduration boxplot without the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'counts')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax = nightriders.plot( y='tripduration',kind='box',showfliers=False)\n",
    "ax.set_ylabel('counts')\n",
    "ax.set_title('trip duration during nightime with outliers removed')\n",
    "ay = dayriders.plot( y='tripduration',kind='box',showfliers=False)\n",
    "ay.set_title('trip duration during daytime with outliers removed')\n",
    "ay.set_ylabel('counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fig 2: The boxplots here show where the bulk of the tripduration is clustered, which is mostly around 2500 seconds\n",
    "\n",
    "\n",
    "#### For the purpose of plotting the histograms we will only be using tripdurations upto 10800 , ie 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Tripduration distribution of dayriders')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = np.arange(61,10800,120)\n",
    "axNight = nightriders['tripduration'].groupby(pd.cut(nightriders['tripduration'],bins)).agg([count_nonzero]).plot(kind='bar',legend=False,figsize=(20,12),color='blue')\n",
    "axNight.set_title('Tripduration distribution of nightriders',size='18')\n",
    "\n",
    "\n",
    "axDay = dayriders['tripduration'].groupby(pd.cut(dayriders['tripduration'],bins)).agg([count_nonzero]).plot(kind='bar',legend=False,color='red',figsize=(20,12))\n",
    "axDay.set_title('Tripduration distribution of dayriders',size='18')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Fig 3: Trip duration distribution of day and night riders **\n",
    "\n",
    "Both distributions look similar , but further testing is required to say it with certainity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the tripduration distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f44d99e7d68>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csDayriders = dayriders.tripduration.groupby(pd.cut(dayriders.tripduration,bins)).agg([count_nonzero]).cumsum()\n",
    "\n",
    "csNightriders = nightriders.tripduration.groupby(pd.cut(nightriders.tripduration,bins)).agg([count_nonzero]).cumsum()\n",
    "\n",
    "\n",
    "#print(np.abs(csDayriders /csDayriders.max() - csNightriders /csNightriders.max()))\n",
    "pl.figure(figsize=(20,10))\n",
    "pl.plot(bins[:-1]+5 ,csDayriders/csDayriders.max(),label='Dayriders',color='r',)\n",
    "pl.plot(bins[:-1]+5 , csNightriders/csNightriders.max(),label='Nightriders')\n",
    "pl.plot(bins[:-1]+5, np.abs(csDayriders /csDayriders.max() - csNightriders /csNightriders.max()), 'k',\n",
    "        label = \"difference\")\n",
    "\n",
    "pl.xlabel(\"Timeduration\")\n",
    "pl.ylabel(\"Normalized Cumulative Number\")\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig 4: The cumulative tripduration distribution of day and night riders.\n",
    "Although there look similar, the difference gets to around  ~ 5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null hypothesis for KS Test\n",
    "\n",
    "## $H_0$ : The samples of the trip duration distribution of dayriders and night riders is the same, p= 0.05\n",
    "\n",
    "##  $\\alpha$ = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ac58e216c37e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mks_2samp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdayriders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tripduration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnightriders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tripduration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "ks = scipy.stats.ks_2samp(pd.Series(dayriders['tripduration']), pd.Series(nightriders['tripduration']))\n",
    "ks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Taking sample size 200 times smaller **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayrider_sample = dayriders.sample(frac=0.005,random_state=13)\n",
    "\n",
    "nightrider_sample = nightriders.sample(frac = 0.005, random_state=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_sample = scipy.stats.ks_2samp(pd.Series(dayrider_sample['tripduration']), pd.Series(nightrider_sample['tripduration']))\n",
    "ks_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Hypothesis testing for sample at alpha_level=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_null_test(m,n,c_alpha,KSstats):\n",
    "    if (ks_sample.statistic > (c_alpha * np.sqrt((m + n )/(m*n)))):\n",
    "        x = c_alpha * np.sqrt((m + n )/(m*n))\n",
    "        print(x)\n",
    "        print(\"Reject the null\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Fail to reject the null\")\n",
    "    print(\"KS Statistic \"+str(KSstats.statistic))\n",
    "    print(\"KS Pvalue \"+str(KSstats.pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_alpha=1.36\n",
    "m=dayrider_sample.size\n",
    "n= nightrider_sample.size\n",
    "ks_null_test(m,n,c_alpha,ks_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_alpha=1.36\n",
    "m=dayriders.size\n",
    "n= nightriders.size\n",
    "ks_null_test(m,n,c_alpha,ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the KS test, since the pvalue < 0.05 ( 0.0 < 0.05) for both cases, we reject the null hypothesis that the distributions of the dayriders and nightriders are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Hypothesis:\n",
    "\n",
    "## $H_0$ : There is no correlation between tripduration of dayriders and nightriders having the same start station id, p =0.05\n",
    "\n",
    "##  $\\alpha$ = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Pearson's test for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the same start station id\n",
    "dayriders_stationid_mean = pd.DataFrame(dayriders.groupby(['start station id'])['tripduration'].mean())\n",
    "nightriders_stationid_mean = pd.DataFrame(nightriders.groupby(['start station id'])['tripduration'].mean())\n",
    "dayriders_stationid_mean.rename(columns={'tripduration' :'meanTripDurationDaytime'},inplace=True)\n",
    "nightriders_stationid_mean.rename(columns={'tripduration' :'meanTripDurationNightime'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([dayriders_stationid_mean, nightriders_stationid_mean], axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pearson_results = scipy.stats.pearsonr(result.meanTripDurationDaytime,result.meanTripDurationNightime)\n",
    "print(pearson_results)\n",
    "\n",
    "if (pearson_results[1] < 0.05) :\n",
    "    print('Reject the null')\n",
    "else:\n",
    "    print('Fail to reject the null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The p value indicates probability of an uncorrelated system producing datasets having the pearson correlation coefficient as least as high as the one generated from this dataset , provided the null hypothesis were true. \n",
    "\n",
    "#### Thus, the low p value indicates that the possibiity is very less\n",
    "\n",
    "Reference: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html#scipy.stats.pearsonr\n",
    "\n",
    "\n",
    "#### There is a positive correlation between tripduration of dayriders and nightriders. \n",
    "\n",
    "#### Therefore, we reject the null hypothesis that there is no correlation between the tripduration of dayriders and nightriders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spearman's test for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmans_result = scipy.stats.spearmanr(result.meanTripDurationDaytime,result.meanTripDurationNightime)\n",
    "print(spearmans_result)\n",
    "\n",
    "if (spearmans_result[1] < 0.05) :\n",
    "    print('Reject the null')\n",
    "else:\n",
    "    print('Fail to reject the null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The p value indicates probability of an uncorrelated system producing datasets having the spearman's correlation coefficient as least as high as the one generated from this dataset,  provided the null hypothesis were true. \n",
    "\n",
    "\n",
    "#### There is a positive correlation between tripduration of dayriders and nightriders. \n",
    "\n",
    "#### The p value is lesser than the alpha value of 0.05 ; which means that we reject the null hypothesis.\n",
    "\n",
    "#### And accept the hypothesis that the two variables are correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an educated guess to map the latitudinal and longitudinal ranges to of Brooklyn and Manhattan respectivey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = df_2016[['birth year', 'end station id']][(df_2016['start station latitude'] >=  40.570066) & \n",
    "                                   (df_2016['start station latitude'] <  40.698649) & \n",
    "                                   (df_2016['start station longitude'] >= -74.036647 )  & \n",
    "                                   (df_2016['start station longitude'] <= -73.924627)]\n",
    "\n",
    "manhattan = df_2016[['birth year', 'end station id']][(df_2016['start station latitude'] >=  40.698649) & \n",
    "                                    (df_2016['start station latitude'] <=  40.861564) & \n",
    "                                    (df_2016['start station longitude'] >= -74.006837 ) & \n",
    "                                    (df_2016['start station longitude'] <= -73.992114)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan['birth year'] = 2016 - manhattan['birth year']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan.rename(columns={'birth year' : 'age'} ,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan.dropna(inplace=True)\n",
    "manhattan.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn['birth year'] = 2016 - brooklyn['birth year']\n",
    "brooklyn.rename(columns={'birth year' : 'age'} ,inplace=True)\n",
    "brooklyn.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_age = np.arange(10,99,5)\n",
    "\n",
    "axbrook = brooklyn.age.groupby(pd.cut(brooklyn.age,bins_age)).agg([count_nonzero]).plot(kind='bar',figsize=(20,12),legend='False',color='green')\n",
    "\n",
    "axbrook.set_title('Age distribution of ridership in brooklyn', size='18')\n",
    "axbrook.set_xlabel('Counts of age of ridership in brooklyn', size='18')\n",
    "axbrook.set_xlabel('Age bins', size='18')\n",
    "axmanhattan = manhattan.age.groupby(pd.cut(manhattan.age,bins_age)).agg([count_nonzero]).plot(kind='bar',figsize=(20,12),legend='False',color='red')\n",
    "\n",
    "axmanhattan.set_title('Age distribution of ridership in manhattan', size='18')\n",
    "axmanhattan.set_xlabel('Counts of age of ridership in manhattan', size='18')\n",
    "axmanhattan.set_xlabel('Age bins', size='18')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fig 5: Age distribution of riders in Manhattan and Brooklyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of the cumulative sum\n",
    "\n",
    "csBrooklyn = brooklyn.age.groupby(pd.cut(brooklyn.age,bins_age)).agg([count_nonzero]).cumsum()\n",
    "csManhattan = manhattan.age.groupby(pd.cut(manhattan.age, bins_age)).agg([count_nonzero]).cumsum()\n",
    "\n",
    "\n",
    "pl.plot(bins_age[:-1] + 5, csBrooklyn / csBrooklyn.max(), label = \"Brooklyn\")\n",
    "pl.plot(bins_age[:-1] + 5, csManhattan / csManhattan.max(), label = \"Manhattan\")\n",
    "pl.plot(bins_age[:-1] + 5, np.sqrt(csBrooklyn / csBrooklyn.max() - csManhattan / csManhattan.max())**2, 'k-',\n",
    "        label = \"difference\")\n",
    "pl.xlabel(\"Age difference between manhattan and brooklyn ridership\")\n",
    "pl.ylabel(\"Normalized Cumulative Number\")\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig 6: The cumulative distribution of age for riders in Manhattan and Brooklyn\n",
    "There seems to be a pronounced difference oin ages of manhattan and brooklyn in the group 30 to 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null hypothesis for KS Test\n",
    "\n",
    "## $H_0$ : The samples of the age distribution for riders in Manhattan and Brooklyn is the same, p= 0.05\n",
    "\n",
    "##  $\\alpha$ = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_age = scipy.stats.ks_2samp(brooklyn.age,manhattan.age)\n",
    "ks_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_alpha=1.36\n",
    "m=brooklyn.size\n",
    "n= manhattan.size\n",
    "ks_null_test(m,n,c_alpha,ks_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn_sample = brooklyn.sample(frac=0.05 , random_state=13)\n",
    "manhattan_sample = manhattan.sample(frac=0.05, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_sample_age = scipy.stats.ks_2samp(brooklyn_sample.age ,manhattan_sample.age )\n",
    "ks_sample_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_alpha=1.36\n",
    "m=brooklyn_sample.size\n",
    "n= manhattan_sample.size\n",
    "ks_null_test(m,n,c_alpha,ks_sample_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the KS test, since the pvalue < 0.05 for both cases, we reject the null hypothesis that the age distributions for riders in Manhattan and Brooklyn are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for Correlation\n",
    "\n",
    "# Null Hypothesis:\n",
    "\n",
    "## $H_0$ : There is no correlation between ages of riders of manhattan and brooklyn having the same end station id, p =0.05\n",
    "\n",
    "##  $\\alpha$ = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pearson's test for correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Hypothesis: There is no correlation between ages of riders of manhattan and brooklyn having the same end station id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby the same endstation id\n",
    "\n",
    "brooklyn_endstations_mean = pd.DataFrame(brooklyn.groupby(['end station id'])['age'].mean())\n",
    "manhattan_endstations_mean = pd.DataFrame(manhattan.groupby(['end station id'])['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn_endstations_mean.rename(columns={'age' :'meanAgeBrooklyn'},inplace=True)\n",
    "manhattan_endstations_mean.rename(columns={'age' :'meanAgeManhattan'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_age = pd.concat([brooklyn_endstations_mean,manhattan_endstations_mean], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsons_age_results = scipy.stats.pearsonr(result_age.meanAgeBrooklyn , result_age.meanAgeManhattan)\n",
    "print(pearsons_age_results)\n",
    "\n",
    "if (pearsons_age_results[1] < 0.05) :\n",
    "    print('Reject the null')\n",
    "else:\n",
    "    print('Fail to reject the null')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The p value indicates probability of an uncorrelated system producing datasets having the pearson correlation coefficient as least as high as the one generated from this dataset,  provided the null hypothesis were true. \n",
    "\n",
    "#### Thus, the low p value indicates that the possibiity is very less\n",
    "\n",
    "Reference: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html#scipy.stats.pearsonr\n",
    "\n",
    "\n",
    "#### There is a positive correlation between ages of riders of manhattan and brooklyn having the same end station id \n",
    "\n",
    "#### Therefore, we reject the null hypothesis that there is no correlation between ages of riders of manhattan and brooklyn having the same end station id "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Spearman's test for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmans_result_age = scipy.stats.spearmanr(result_age.meanAgeBrooklyn,result_age.meanAgeManhattan)\n",
    "print(spearmans_result_age)\n",
    "if (spearmans_result_age[1] < 0.05) :\n",
    "    print('Reject the null')\n",
    "else:\n",
    "    print('Fail to reject the null')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The p value indicates probability of an uncorrelated system producing datasets having the spearman correlation coefficient as least as high as the one generated from this dataset , provided the null hypothesis were true. \n",
    "\n",
    "#### Thus, the low p value indicates that the possibiity is very less\n",
    "\n",
    "\n",
    "\n",
    "#### There is a positive correlation between ages of riders of manhattan and brooklyn having the same end station id \n",
    "\n",
    "#### Therefore, we reject the null hypothesis that there is no correlation between ages of riders of manhattan and brooklyn having the same end station id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python3",
   "language": "python",
   "name": "pui2016_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
